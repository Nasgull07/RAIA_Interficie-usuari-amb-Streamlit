import streamlit as st
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from datetime import datetime

st.set_page_config(page_title="Entrenamiento del Modelo", page_icon="ü§ñ", layout="wide")

from utils.data_loader import load_train_data, load_test_data
from utils.model_builder import (
    train_model,
    save_model,
    load_model,
    model_exists,
    get_model_info,
    TF_AVAILABLE
)

st.title("ü§ñ Entrenamiento del Modelo CNN")
st.markdown("""
Entrena una Red Neuronal Convolucional para reconocer letras manuscritas del dataset EMNIST.
""")

# Verificar TensorFlow
if not TF_AVAILABLE:
    st.error("""
    ‚ö†Ô∏è **TensorFlow no est√° instalado**
    
    Para usar esta funcionalidad, instala TensorFlow:
    ```bash
    pip install tensorflow
    ```
    """)
    st.stop()

# Sidebar con configuraci√≥n de entrenamiento
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n de Entrenamiento")
    
    # Widgets para hiperpar√°metros
    st.subheader("Datos")
    train_samples = st.number_input(
        "Muestras de entrenamiento",
        min_value=1000,
        max_value=100000,
        value=10000,
        step=1000,
        help="N√∫mero de muestras para entrenar"
    )
    
    val_split = st.slider(
        "% Validaci√≥n",
        min_value=10,
        max_value=30,
        value=20,
        help="Porcentaje de datos para validaci√≥n"
    )
    
    st.subheader("Hiperpar√°metros")
    epochs = st.slider(
        "√âpocas",
        min_value=1,
        max_value=20,
        value=10,
        help="N√∫mero de √©pocas de entrenamiento"
    )
    
    batch_size = st.select_slider(
        "Tama√±o de batch",
        options=[32, 64, 128, 256],
        value=128,
        help="Tama√±o del batch"
    )
    
    st.divider()
    
    # Estado del modelo actual
    st.subheader("üìä Modelo Actual")
    if model_exists():
        st.success("‚úÖ Modelo existente encontrado")
        model_info = get_model_info()
        if model_info:
            st.metric("Precisi√≥n", f"{model_info['val_accuracy']*100:.2f}%")
            st.metric("√âpocas previas", model_info['epochs_trained'])
        
        st.warning("‚ö†Ô∏è Entrenar sobrescribir√° el modelo actual")
    else:
        st.info("‚ÑπÔ∏è No hay modelo previo")

# Inicializar session_state
if 'training_complete' not in st.session_state:
    st.session_state.training_complete = False
if 'training_history' not in st.session_state:
    st.session_state.training_history = None
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = None

# Bot√≥n de entrenamiento
col1, col2, col3 = st.columns([1, 2, 1])

with col2:
    if st.button("üöÄ Iniciar Entrenamiento", type="primary", use_container_width=True):
        st.session_state.training_complete = False
        st.session_state.training_history = None
        
        # Contenedor para progreso
        progress_container = st.container()
        
        with progress_container:
            # Cargar datos
            st.info("üì• Cargando datos...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("Cargando dataset de entrenamiento...")
            X_train_full, y_train_full = load_train_data(sample_size=train_samples)
            progress_bar.progress(20)
            
            if X_train_full is None or y_train_full is None:
                st.error("‚ùå Error al cargar los datos")
                st.stop()
            
            # Dividir en train y validation
            status_text.text("Preparando datos de validaci√≥n...")
            val_size = int(len(X_train_full) * (val_split / 100))
            indices = np.random.permutation(len(X_train_full))
            
            train_idx = indices[val_size:]
            val_idx = indices[:val_size]
            
            X_train = X_train_full[train_idx]
            y_train = y_train_full[train_idx]
            X_val = X_train_full[val_idx]
            y_val = y_train_full[val_idx]
            
            progress_bar.progress(40)
            
            st.success(f"‚úÖ Datos cargados: {len(X_train)} entrenamiento, {len(X_val)} validaci√≥n")
            
            # Entrenar modelo
            status_text.text("üèãÔ∏è Entrenando modelo CNN...")
            
            # Crear contenedor para m√©tricas en tiempo real
            metrics_container = st.empty()
            
            model, history = train_model(
                X_train, y_train,
                X_val, y_val,
                epochs=epochs,
                batch_size=batch_size
            )
            
            progress_bar.progress(90)
            
            if model is not None and history is not None:
                # Guardar modelo
                status_text.text("üíæ Guardando modelo...")
                save_model(model, history)
                progress_bar.progress(100)
                
                st.session_state.training_complete = True
                st.session_state.training_history = history
                st.session_state.model_trained = model
                
                status_text.empty()
                st.success("‚úÖ ¬°Entrenamiento completado con √©xito!")
                st.balloons()
                
                st.rerun()
            else:
                st.error("‚ùå Error durante el entrenamiento")

# Mostrar resultados si el entrenamiento est√° completo
if st.session_state.training_complete and st.session_state.training_history is not None:
    st.divider()
    st.header("üìä Resultados del Entrenamiento")
    
    history = st.session_state.training_history
    
    # M√©tricas finales
    col1, col2, col3, col4 = st.columns(4)
    
    final_train_acc = history.history['accuracy'][-1]
    final_val_acc = history.history['val_accuracy'][-1]
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]
    
    col1.metric("Precisi√≥n Entrenamiento", f"{final_train_acc*100:.2f}%")
    col2.metric("Precisi√≥n Validaci√≥n", f"{final_val_acc*100:.2f}%")
    col3.metric("P√©rdida Entrenamiento", f"{final_train_loss:.4f}")
    col4.metric("P√©rdida Validaci√≥n", f"{final_val_loss:.4f}")
    
    # Gr√°ficos de entrenamiento
    st.subheader("üìà Curvas de Aprendizaje")
    
    tab1, tab2 = st.tabs(["Precisi√≥n", "P√©rdida"])
    
    with tab1:
        # Gr√°fico de precisi√≥n
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            y=history.history['accuracy'],
            name='Entrenamiento',
            mode='lines+markers',
            line=dict(color='blue', width=2)
        ))
        
        fig.add_trace(go.Scatter(
            y=history.history['val_accuracy'],
            name='Validaci√≥n',
            mode='lines+markers',
            line=dict(color='red', width=2)
        ))
        
        fig.update_layout(
            title='Precisi√≥n durante el Entrenamiento',
            xaxis_title='√âpoca',
            yaxis_title='Precisi√≥n',
            height=400,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # Gr√°fico de p√©rdida
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            y=history.history['loss'],
            name='Entrenamiento',
            mode='lines+markers',
            line=dict(color='blue', width=2)
        ))
        
        fig.add_trace(go.Scatter(
            y=history.history['val_loss'],
            name='Validaci√≥n',
            mode='lines+markers',
            line=dict(color='red', width=2)
        ))
        
        fig.update_layout(
            title='P√©rdida durante el Entrenamiento',
            xaxis_title='√âpoca',
            yaxis_title='P√©rdida',
            height=400,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # An√°lisis del entrenamiento
    st.subheader("üîç An√°lisis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Mejora por √©poca
        improvements = []
        for i in range(1, len(history.history['val_accuracy'])):
            imp = history.history['val_accuracy'][i] - history.history['val_accuracy'][i-1]
            improvements.append(imp)
        
        if improvements:
            avg_improvement = np.mean(improvements)
            st.metric(
                "Mejora promedio por √©poca",
                f"{avg_improvement*100:.2f}%",
                delta=f"{'Positiva' if avg_improvement > 0 else 'Negativa'}"
            )
    
    with col2:
        # Overfitting check
        overfit_gap = final_train_acc - final_val_acc
        st.metric(
            "Gap Entrenamiento-Validaci√≥n",
            f"{overfit_gap*100:.2f}%",
            help="Diferencia entre precisi√≥n de entrenamiento y validaci√≥n"
        )
        
        if overfit_gap > 0.1:
            st.warning("‚ö†Ô∏è Posible overfitting detectado")
        elif overfit_gap < 0.05:
            st.success("‚úÖ Buen balance entre entrenamiento y validaci√≥n")
    
    # Recomendaciones
    st.subheader("üí° Recomendaciones")
    
    if final_val_acc < 0.7:
        st.info("""
        üìö **Baja precisi√≥n detectada**
        - Aumenta el n√∫mero de muestras de entrenamiento
        - Incrementa el n√∫mero de √©pocas
        - Considera ajustar la arquitectura del modelo
        """)
    elif final_val_acc >= 0.7 and final_val_acc < 0.85:
        st.success("""
        üëç **Rendimiento aceptable**
        - El modelo funciona bien para casos b√°sicos
        - Puedes mejorar incrementando √©pocas o datos
        """)
    else:
        st.success("""
        üéâ **Excelente rendimiento**
        - El modelo est√° listo para producci√≥n
        - Prueba el modelo en la p√°gina "Dibuja y Reconoce"
        """)

# Modelo actual
elif model_exists():
    st.info("""
    ‚ÑπÔ∏è **Hay un modelo previamente entrenado**
    
    Puedes:
    - Entrenar un nuevo modelo (sobrescribir√° el actual)
    - Ir a la p√°gina "Dibuja y Reconoce" para probarlo
    """)
    
    st.subheader("üìä Informaci√≥n del Modelo Actual")
    model_info = get_model_info()
    
    if model_info:
        col1, col2, col3 = st.columns(3)
        col1.metric("Precisi√≥n en Validaci√≥n", f"{model_info['val_accuracy']*100:.2f}%")
        col2.metric("√âpocas Entrenadas", model_info['epochs_trained'])
        col3.metric("P√©rdida Final", f"{model_info['val_loss']:.4f}")

else:
    st.info("""
    üëÜ **Configura los par√°metros y comienza el entrenamiento**
    
    Ajusta los hiperpar√°metros en el panel lateral y haz clic en "Iniciar Entrenamiento".
    
    **Recomendaciones iniciales:**
    - Comienza con 5,000-10,000 muestras para pruebas r√°pidas
    - Usa 5-10 √©pocas para el primer entrenamiento
    - Una vez satisfecho, entrena con m√°s datos y √©pocas
    """)

st.divider()
st.caption("""
üí° **Elementos integrados**: 
- Widgets (sliders, number_input, select_slider) para configuraci√≥n
- Progress bars y spinners para feedback visual
- Cache de datos para optimizaci√≥n
- Session state para mantener resultados del entrenamiento
- Persistencia del modelo en disco
""")
